{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fcb126-536f-49c1-ad1a-93121905ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this import so Term and Sentence\n",
    "# can talk about each other\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pprint\n",
    "from typing import NamedTuple\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9aa33-e4dd-49cc-8a80-9c200f8c12d3",
   "metadata": {},
   "source": [
    "## Define the `Term` and `Sentence` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98a121a-39f8-4c42-8548-7d5c1431efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Term(NamedTuple):\n",
    "    \"\"\"This basically represents all the data needed\n",
    "    to generate an Anki flaschard for one word / phrase\n",
    "    in the target language\n",
    "    \"\"\"\n",
    "    text: str  # the word / phrase in the target language.\n",
    "    translation: str  # the English translation of the word / phrase.\n",
    "    sentence_ids: list[str]  # list of Tatoeba sentence ids for\n",
    "                             # the example sentences that go with this term.\n",
    "                             # This should maybe be a list of ints instead of strs.\n",
    "    sentences: list[Sentence]  # Objects representing the example sentences.\n",
    "\n",
    "# This being a named tuple is actually a problem\n",
    "# bc when it's initialized it doesn't have all of\n",
    "# its data. Like I want to add the audio id later\n",
    "# This could be a types.SimpleNamespace but I want to\n",
    "# enforce a specific constructor.\n",
    "# TODO: better print function\n",
    "class Sentence:\n",
    "    tatoeba_id: str  # Tatoeba sentence id for this sentence.\n",
    "                     # Should maybe be a str.\n",
    "    text: str  # The text of the sentence.\n",
    "    translations: list[str] | None  # English translations of this sentence.\n",
    "                                    # Not all sentences will have translations,\n",
    "                                    # so this value could be None.\n",
    "    audio_id: str | None  # Tatoeba audio id for this sentence. Not all\n",
    "                   # sentences will have audios. If there is no\n",
    "                   # audio, this will be None. This should maybe be an int.\n",
    "    parent_term: Term  # A reference to the vocab term that this sentence\n",
    "                       # serves as an example for. This is useful in the\n",
    "                       # data generation part. TODO: This actually isn't necessary\n",
    "    \n",
    "    def __init__(self, tatoeba_id, text, parent_term):\n",
    "        self.tatoeba_id = tatoeba_id\n",
    "        self.text = text\n",
    "        self.parent_term = parent_term\n",
    "\n",
    "        self.translations = []\n",
    "        self.audio_id = None\n",
    "\n",
    "    def print(self):\n",
    "        #TODO make this reasonable\n",
    "        attr_dict = {\n",
    "            'tatoeba_id': self.tatoeba_id,\n",
    "            'text': self.text,\n",
    "            'translations': self.translations,\n",
    "            'audio_id': self.audio_id\n",
    "        }\n",
    "        return pprint.pp(attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c319bfbf-2fd6-49db-b766-8860451e06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tsv(process_fn, filepath_str, encoding='utf-8-sig'):\n",
    "    \"\"\"Call ROW_FN on each row of a TSV file\"\"\"\n",
    "    with open(filepath_str, newline='', encoding=encoding) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        return process_fn(reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb85d2-8cb7-47e6-aa9a-da610b277b2e",
   "metadata": {},
   "source": [
    "## Turn the vocab list `tsv` file into list of `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5ae747-7c9c-4e26-aecb-52a1f3e5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vocab_list(tsv_reader, skip_header=True, validation=True):\n",
    "    terms = []\n",
    "    if skip_header:\n",
    "        header = next(tsv_reader)\n",
    "    for row in tsv_reader:\n",
    "        word_de, word_en = row[:2]\n",
    "        sentence_ids = [s for s in row[2:] if s]\n",
    "        one_term = Term(word_de, word_en, sentence_ids, [])\n",
    "        terms.append(one_term)\n",
    "    if validation:\n",
    "        for term in terms:\n",
    "            # every term should have at least\n",
    "            # one sentence_id and one translation\n",
    "            assert term.sentence_ids\n",
    "            assert term.translation\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725c4b51-d3dd-4efb-aa49-bd288f7a6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list_file = './NW_7_Days-and-times - Tageszeiten.tsv'\n",
    "terms = process_tsv(process_vocab_list, vocab_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9279b0-2eee-47e7-a234-c273cb348c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Term(text='der Abend, die Abende', translation='evening', sentence_ids=['998'], sentences=[]),\n",
       " Term(text='das Abendessen, die Abendessen', translation='dinner', sentence_ids=['341418'], sentences=[]),\n",
       " Term(text='am Morgen', translation='in the morning', sentence_ids=['347433'], sentences=[]),\n",
       " Term(text='jemanden an|rufen', translation='to call someone', sentence_ids=['873078'], sentences=[]),\n",
       " Term(text='der Apfel, die Äpfel', translation='apple', sentence_ids=['367095'], sentences=[]),\n",
       " Term(text='etwas auf|räumen', translation='to clean up something; to tidy up something', sentence_ids=['618818'], sentences=[]),\n",
       " Term(text='aus|gehen', translation='to go out', sentence_ids=['882822'], sentences=[]),\n",
       " Term(text='auf|stehen', translation='to get up', sentence_ids=['365619'], sentences=[]),\n",
       " Term(text='etwas ein|kaufen', translation='to buy/shop for something', sentence_ids=['3567432'], sentences=[]),\n",
       " Term(text='fast immer', translation='almost always', sentence_ids=['2571282'], sentences=[]),\n",
       " Term(text='die Flöte, die Flöten', translation='flute', sentence_ids=['11932738'], sentences=[]),\n",
       " Term(text='das Frühstück, die Frühstücke', translation='breakfast', sentence_ids=['450713'], sentences=[]),\n",
       " Term(text='frühstücken', translation='to eat breakfast', sentence_ids=['470147'], sentences=[]),\n",
       " Term(text='das Gemüse', translation='vegetables', sentence_ids=['8320425'], sentences=[]),\n",
       " Term(text='jeden Tag', translation='every day', sentence_ids=['784324'], sentences=[]),\n",
       " Term(text='manchmal', translation='sometimes', sentence_ids=['917600'], sentences=[]),\n",
       " Term(text='meistens', translation='most of the time', sentence_ids=['365619'], sentences=[]),\n",
       " Term(text='das Mittagessen, die Mittagessen', translation='lunch', sentence_ids=['10513933'], sentences=[]),\n",
       " Term(text='der Morgen, die Morgen', translation='morning', sentence_ids=['1012'], sentences=[]),\n",
       " Term(text='das Müsli, die Müslis', translation='granola', sentence_ids=['10919429'], sentences=[]),\n",
       " Term(text='der Nachmittag, die Nachmittage', translation='afternoon', sentence_ids=['989712', '1807249'], sentences=[]),\n",
       " Term(text='die Nacht, die Näche', translation='night', sentence_ids=['445863'], sentences=[]),\n",
       " Term(text='nie', translation='never', sentence_ids=['622511'], sentences=[]),\n",
       " Term(text='normalerweise', translation='normally', sentence_ids=['368788'], sentences=[]),\n",
       " Term(text='oft', translation='often', sentence_ids=['236457'], sentences=[]),\n",
       " Term(text='der Vormittag, die Vormittage', translation='morning; before noon', sentence_ids=['7580996'], sentences=[]),\n",
       " Term(text='wichtig', translation='important', sentence_ids=['8080381'], sentences=[]),\n",
       " Term(text='wissen', translation='to know', sentence_ids=['758482'], sentences=[]),\n",
       " Term(text='Zähne putzen', translation=\"to brush one's teeth\", sentence_ids=['601450'], sentences=[])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366c2e7-32b9-4480-884c-a8b5fed1823b",
   "metadata": {},
   "source": [
    "## Now add the sentence data to the `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7953419-26d7-49bb-a982-77987baa9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentences(tsvreader, terms, validate=True):\n",
    "    \n",
    "    # a simple many-to-one mapping of\n",
    "    # tatoeba sentence id -> [Terms]\n",
    "    terms_by_id = defaultdict(list)\n",
    "    for t in terms:\n",
    "        for sentence_id in t.sentence_ids:\n",
    "            terms_by_id[sentence_id].append(t)\n",
    "    \n",
    "    for row in tsvreader:\n",
    "        sentence_id, text = row[0], row[2]\n",
    "        if sentence_id in terms_by_id:\n",
    "            for t in terms_by_id[sentence_id]:\n",
    "                sentence = Sentence(sentence_id, text, t)\n",
    "                t.sentences.append(sentence)\n",
    "        # could possibly speed up performance here by\n",
    "        # deleting the key (sentence_id) after a hit\n",
    "        # and then checking on each loop iteration to\n",
    "        # see if there are any keys left.\n",
    "        # tbh this feels like a good problem to solve\n",
    "        # with a queue\n",
    "    \n",
    "    if validate:\n",
    "        for t in terms:\n",
    "            # all terms should have at least one sentence\n",
    "            if not t.sentences:\n",
    "                raise AssertionError(f\"found no sentences for {t}\")\n",
    "            for s in t.sentences:\n",
    "                assert s.tatoeba_id\n",
    "                assert s.text\n",
    "                assert s.tatoeba_id in t.sentence_ids\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f65a70-edd3-467c-b493-b9676c123555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = 'deu_sentences.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e37d418-4b3c-4aee-a7ab-5d45a4194a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_sentences(x, terms, True), sentences_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebc642-a7c3-42dc-a113-2bf0253bd017",
   "metadata": {},
   "source": [
    "## Add translation data to the `Terms`\n",
    "Provided that there is translation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7cd059-7a3b-463c-97e9-536a33083ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_translations(tsvreader, terms, limit=2):\n",
    "    sentences_by_id = defaultdict(list)\n",
    "    for t in terms:\n",
    "        for s in t.sentences:\n",
    "            sentences_by_id[s.tatoeba_id].append(s)\n",
    "    for row in tsvreader:\n",
    "        sentence_id = row[0]\n",
    "        translation = row[3]\n",
    "        if sentence_id in sentences_by_id:\n",
    "            sentences = sentences_by_id[sentence_id]\n",
    "            for s in sentences:\n",
    "                if len(s.translations) < limit:\n",
    "                    s.translations.append(translation)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c20499a1-5856-4287-b1b9-51568c688c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_file = 'Sentence pairs in German-English - 2024-12-13.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba7e613-dcfc-4feb-9f3a-66f52106476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_translations(x, terms), translations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e75a0-2b96-419a-9de1-1fd8f5db346d",
   "metadata": {},
   "source": [
    "## Add audio data to the `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14dc1df6-34ef-499b-9952-e52c57750947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_audio_ids(tsvreader, terms):\n",
    "    sentence_by_id = {}\n",
    "    for t in terms:\n",
    "        for s in t.sentences:\n",
    "            sentence_by_id[s.tatoeba_id] = s\n",
    "    for row in tsvreader:\n",
    "        sentence_id = row[0]\n",
    "        audio_id = row[1]\n",
    "        if sentence_id in sentence_by_id:\n",
    "            s = sentence_by_id[sentence_id]\n",
    "            s.audio_id = audio_id\n",
    "            # Delete the key in case the data file\n",
    "            # has multiple audio ids for this sentence\n",
    "            sentence_by_id.pop(sentence_id)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be0b522-9601-4721-bc6e-bda99083a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_id_file = 'sentences_with_audio.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a5b5e4-bbb0-4466-8925-d479eccfec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_audio_ids(x, terms), audio_id_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3566892-1881-4d14-bf20-c858a325371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tatoeba_id': '998',\n",
      " 'text': 'Ich dusche gewöhnlich abends.',\n",
      " 'translations': ['I usually take a shower in the evening.',\n",
      "                  'I usually shower at night.'],\n",
      " 'audio_id': '634'}\n"
     ]
    }
   ],
   "source": [
    "terms[0].sentences[0].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e8e9eee-de13-49f0-851c-dce588dffc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_audios = [t for t in terms if any(map(lambda s: not s.audio_id, t.sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f96aeb6a-656e-43cd-80af-f528aad7c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Term(text='am Morgen', translation='in the morning', sentence_ids=['347433'], sentences=[<__main__.Sentence object at 0x000002053DE91340>]), Term(text='auf|stehen', translation='to get up', sentence_ids=['365619'], sentences=[<__main__.Sentence object at 0x000002053DE913A0>]), Term(text='etwas ein|kaufen', translation='to buy/shop for something', sentence_ids=['3567432'], sentences=[<__main__.Sentence object at 0x000002053DE92210>]), Term(text='fast immer', translation='almost always', sentence_ids=['2571282'], sentences=[<__main__.Sentence object at 0x000002053DE92270>]), Term(text='die Flöte, die Flöten', translation='flute', sentence_ids=['11932738'], sentences=[<__main__.Sentence object at 0x000002053DE924E0>]), Term(text='das Mittagessen, die Mittagessen', translation='lunch', sentence_ids=['10513933'], sentences=[<__main__.Sentence object at 0x000002053DE92300>]), Term(text='das Müsli, die Müslis', translation='granola', sentence_ids=['10919429'], sentences=[<__main__.Sentence object at 0x000002053DE925A0>]), Term(text='der Nachmittag, die Nachmittage', translation='afternoon', sentence_ids=['989712', '1807249'], sentences=[<__main__.Sentence object at 0x000002053DE92240>, <__main__.Sentence object at 0x000002053DE922D0>])]\n"
     ]
    }
   ],
   "source": [
    "print(no_audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bde1322-80af-4ece-8711-1c32aaf25cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tatoeba_id': '347433',\n",
      " 'text': 'Könnte ich am Morgen duschen?',\n",
      " 'translations': ['May I take a shower in the morning?'],\n",
      " 'audio_id': None}\n"
     ]
    }
   ],
   "source": [
    "no_audios[0].sentences[0].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4a528a-1f39-42e1-9d04-a055ea7b8677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tatoeba_id': '365619',\n",
      " 'text': 'Ich stehe meistens um acht auf.',\n",
      " 'translations': ['I usually get up at eight.',\n",
      "                  \"I usually get up at eight o'clock.\"],\n",
      " 'audio_id': None}\n"
     ]
    }
   ],
   "source": [
    "no_audios[1].sentences[0].print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb44d2-4f30-4210-be42-f304c41900f8",
   "metadata": {},
   "source": [
    "## Write terms to Anki-readble `.tsv`\n",
    "We'll only take two translations per sentence.\n",
    "The file should look something like\n",
    "```\n",
    "word_de | word_en | tags| sentence1_de | audio1_id | sentence1_tr1 | sentence1_tr2 | sentence2_de audio2_id | sentence2_tr1 | sentence2_tr2 | tags\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6643e778-bf76-4d8e-b051-6fba46620e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anki_tsv(tsvwriter,\n",
    "                    terms,\n",
    "                    max_translations=2,  # max translations of word_en\n",
    "                    max_sentences=2,  # max example sentences\n",
    "                    format_audio=True, \n",
    "                    headers=None,\n",
    "                    tags=None):\n",
    "    if not headers:\n",
    "        headers = ['word_de',\n",
    "                   'word_en',\n",
    "                   'tags',\n",
    "                   'sentence1_de',\n",
    "                   'audio1_id',\n",
    "                   'sentence1_tr1',\n",
    "                   'sentence1_tr2',\n",
    "                   'sentence2_de',\n",
    "                   'audio2_id',\n",
    "                   'sentence2_tr1',\n",
    "                   'sentence2_tr2']\n",
    "    tsvwriter.writerow(headers)\n",
    "    for t in terms:\n",
    "        row = []  # one row per term\n",
    "        row.append(t.text)\n",
    "        row.append(t.translation)\n",
    "        row.append(tags)\n",
    "        for s in t.sentences[:max_sentences]:\n",
    "            row.append(s.text)\n",
    "            if s.audio_id and format_audio:\n",
    "                row.append('[sound:{}.mp3]'.format(s.audio_id))\n",
    "            elif s.audio_id:\n",
    "                row.append(s.audio_id)\n",
    "            else:\n",
    "                row.append('')\n",
    "            \n",
    "            row.extend(s.translations[:max_translations])\n",
    "            # need row padding in case there are less translations\n",
    "            # than the maximum allowed\n",
    "            row_padding = [''] * max(0, max_translations - len(s.translations))\n",
    "            row.extend(row_padding)\n",
    "        tsvwriter.writerow(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e2ac899-1b13-431c-9fb3-19a0ef79e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tsv = './tageszeiten_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "791cd46c-feae-4cd9-be00-ca4553c025be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_tsv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    tsvwriter = csv.writer(f, delimiter='\\t')\n",
    "    tags = ['python::refactor-test nw::days-and-times::tagezeiten']\n",
    "    create_anki_tsv(tsvwriter, terms, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073b19c-567e-44b5-bc57-1d02a2ea297c",
   "metadata": {},
   "source": [
    "## Download Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff1d5474-508c-4497-96e2-84884c06c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIRECTORY = './days_and_times/tageszeiten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2cdb4a6-bbe0-450c-be58-2ead618b2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mp3s(terms,\n",
    "                 audio_url_template='https://tatoeba.org/audio/download/{0}',\n",
    "                 audio_directory=AUDIO_DIRECTORY):\n",
    "    \n",
    "    sentences = [s for t in terms for s in t.sentences if s.audio_id]\n",
    "    for s in sentences:\n",
    "        audio_id = s.audio_id\n",
    "        request_url = audio_url_template.format(audio_id)\n",
    "        mp3data_request = requests.get(request_url)\n",
    "        mp3data = mp3data_request.content\n",
    "        with open(f'{audio_directory}/{audio_id}.mp3', 'wb') as mp3file:\n",
    "            mp3file.write(mp3data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab6bc0c7-bef1-4e2b-bc3b-a6c7871e1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_mp3s(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260dd359-43da-4a8b-91a1-591ab4a09865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatoeba_de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
