{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a015c5ca-8822-429e-9678-cf2a04206b60",
   "metadata": {},
   "source": [
    "## Some Notes\n",
    "### After looking at the cards\n",
    "* Having two translations seems like overkill. One is usually fine. Other translations are just slight variations in the translation.\n",
    "### Other ideas\n",
    "* Highlight the vocab word in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80fcb126-536f-49c1-ad1a-93121905ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this import so Term and Sentence\n",
    "# can talk about each other\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pprint\n",
    "from typing import NamedTuple\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9aa33-e4dd-49cc-8a80-9c200f8c12d3",
   "metadata": {},
   "source": [
    "## Define the `Term` and `Sentence` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f98a121a-39f8-4c42-8548-7d5c1431efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Term(NamedTuple):\n",
    "    \"\"\"This basically represents all the data needed\n",
    "    to generate an Anki flaschard for one word / phrase\n",
    "    in the target language\n",
    "    \"\"\"\n",
    "    text: str  # the word / phrase in the target language.\n",
    "    translation: str  # the English translation of the word / phrase.\n",
    "    sentence_ids: list[str]  # list of Tatoeba sentence ids for\n",
    "                             # the example sentences that go with this term.\n",
    "                             # This should maybe be a list of ints instead of strs.\n",
    "    sentences: list[Sentence]  # Objects representing the example sentences.\n",
    "\n",
    "# This being a named tuple is actually a problem\n",
    "# bc when it's initialized it doesn't have all of\n",
    "# its data. Like I want to add the audio id later\n",
    "# This could be a types.SimpleNamespace but I want to\n",
    "# enforce a specific constructor.\n",
    "# TODO: better print function\n",
    "class Sentence:\n",
    "    tatoeba_id: str  # Tatoeba sentence id for this sentence.\n",
    "                     # Should maybe be a str.\n",
    "    text: str  # The text of the sentence.\n",
    "    translations: list[str] | None  # English translations of this sentence.\n",
    "                                    # Not all sentences will have translations,\n",
    "                                    # so this value could be None.\n",
    "    audio_id: str | None  # Tatoeba audio id for this sentence. Not all\n",
    "                   # sentences will have audios. If there is no\n",
    "                   # audio, this will be None. This should maybe be an int.\n",
    "    parent_term: Term  # A reference to the vocab term that this sentence\n",
    "                       # serves as an example for. This is useful in the\n",
    "                       # data generation part. TODO: This actually isn't necessary\n",
    "    \n",
    "    def __init__(self, tatoeba_id, text, parent_term):\n",
    "        self.tatoeba_id = tatoeba_id\n",
    "        self.text = text\n",
    "        self.parent_term = parent_term\n",
    "\n",
    "        self.translations = []\n",
    "        self.audio_id = None\n",
    "\n",
    "    def print(self):\n",
    "        #TODO make this reasonable\n",
    "        attr_dict = {\n",
    "            'tatoeba_id': self.tatoeba_id,\n",
    "            'text': self.text,\n",
    "            'translations': self.translations,\n",
    "            'audio_id': self.audio_id\n",
    "        }\n",
    "        return pprint.pp(attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c319bfbf-2fd6-49db-b766-8860451e06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tsv(process_fn, filepath_str, encoding='utf-8-sig'):\n",
    "    \"\"\"Call ROW_FN on each row of a TSV file\"\"\"\n",
    "    with open(filepath_str, newline='', encoding=encoding) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        return process_fn(reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb85d2-8cb7-47e6-aa9a-da610b277b2e",
   "metadata": {},
   "source": [
    "## Turn the vocab list `tsv` file into list of `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b5ae747-7c9c-4e26-aecb-52a1f3e5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vocab_list(tsv_reader, skip_header=True, validation=True):\n",
    "    terms = []\n",
    "    if skip_header:\n",
    "        header = next(tsv_reader)\n",
    "    for row in tsv_reader:\n",
    "        word_de, word_en = row[:2]\n",
    "        sentence_ids = [s for s in row[2:] if s]\n",
    "        one_term = Term(word_de, word_en, sentence_ids, [])\n",
    "        terms.append(one_term)\n",
    "    if validation:\n",
    "        for term in terms:\n",
    "            # every term should have at least\n",
    "            # one sentence_id and one translation\n",
    "            assert term.sentence_ids\n",
    "            assert term.translation\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725c4b51-d3dd-4efb-aa49-bd288f7a6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list_file = './appointments/wie-spät-ist-es.tsv'\n",
    "terms = process_tsv(process_vocab_list, vocab_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9279b0-2eee-47e7-a234-c273cb348c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Term(text='ab wann', translation='from when (on)', sentence_ids=['344633', '383114'], sentences=[]),\n",
       " Term(text='allein', translation='alone', sentence_ids=['1496802'], sentences=[]),\n",
       " Term(text='am', translation='on', sentence_ids=['1990130'], sentences=[]),\n",
       " Term(text='Auf Wiederhören!', translation='Goodbye! (on the phone, friendly)', sentence_ids=['5663080'], sentences=[]),\n",
       " Term(text='die Dreiviertelstunde, die Dreiviertelstunden', translation='three-quarters of an hour; 45 minutes', sentence_ids=['1046089'], sentences=[]),\n",
       " Term(text='der Fisch, die Fische', translation='fish', sentence_ids=['343406'], sentences=[]),\n",
       " Term(text='geöffnet haben', translation='to be open (store, business, etc)', sentence_ids=['1841947', '7466831'], sentences=[]),\n",
       " Term(text='geschlossen haben', translation='to be closed (store, business, etc)', sentence_ids=['554233'], sentences=[]),\n",
       " Term(text='halbe Stunde', translation='half an hour', sentence_ids=['669855'], sentences=[]),\n",
       " Term(text='kurz nach', translation='shortly after', sentence_ids=['678771'], sentences=[]),\n",
       " Term(text='kurz vor', translation='shortly before', sentence_ids=['2925014'], sentences=[]),\n",
       " Term(text='leider', translation='unfortunately', sentence_ids=['5327593', '6487367'], sentences=[]),\n",
       " Term(text='die Minute, die Minuten', translation='minute', sentence_ids=['701644'], sentences=[]),\n",
       " Term(text='die Stunde, die Stunden', translation='hour', sentence_ids=['585208'], sentences=[]),\n",
       " Term(text='die Suppe, die Suppen', translation='soup', sentence_ids=['1248048'], sentences=[]),\n",
       " Term(text='die Veirtelstunde, die Viertelstunden', translation='quarter of an hour', sentence_ids=['614062'], sentences=[]),\n",
       " Term(text='Viertel nach', translation='quarter past', sentence_ids=['344350'], sentences=[]),\n",
       " Term(text='Viertel vor', translation='quarter to', sentence_ids=['1439109'], sentences=[]),\n",
       " Term(text='(auf jemanden/etwas) warten', translation='to wait (for someone, something)', sentence_ids=['8313691'], sentences=[]),\n",
       " Term(text='der Zug, die Züge', translation='train', sentence_ids=['340900'], sentences=[])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366c2e7-32b9-4480-884c-a8b5fed1823b",
   "metadata": {},
   "source": [
    "## Now add the sentence data to the `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7953419-26d7-49bb-a982-77987baa9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentences(tsvreader, terms, validate=True):\n",
    "    \n",
    "    # a simple many-to-one mapping of\n",
    "    # tatoeba sentence id -> [Terms]\n",
    "    terms_by_id = defaultdict(list)\n",
    "    for t in terms:\n",
    "        for sentence_id in t.sentence_ids:\n",
    "            terms_by_id[sentence_id].append(t)\n",
    "    \n",
    "    for row in tsvreader:\n",
    "        sentence_id, text = row[0], row[2]\n",
    "        if sentence_id in terms_by_id:\n",
    "            for t in terms_by_id[sentence_id]:\n",
    "                sentence = Sentence(sentence_id, text, t)\n",
    "                t.sentences.append(sentence)\n",
    "        # could possibly speed up performance here by\n",
    "        # deleting the key (sentence_id) after a hit\n",
    "        # and then checking on each loop iteration to\n",
    "        # see if there are any keys left.\n",
    "        # tbh this feels like a good problem to solve\n",
    "        # with a queue\n",
    "    \n",
    "    if validate:\n",
    "        for t in terms:\n",
    "            # all terms should have at least one sentence\n",
    "            if not t.sentences:\n",
    "                raise AssertionError(f\"found no sentences for {t}\")\n",
    "            for s in t.sentences:\n",
    "                assert s.tatoeba_id\n",
    "                assert s.text\n",
    "                assert s.tatoeba_id in t.sentence_ids\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4f65a70-edd3-467c-b493-b9676c123555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = 'deu_sentences.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e37d418-4b3c-4aee-a7ab-5d45a4194a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_sentences(x, terms, True), sentences_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af43cbaf-728c-4c96-bafe-ab707d224cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tatoeba_id': '1496802',\n",
      " 'text': 'Tom hat allein gegessen.',\n",
      " 'translations': [],\n",
      " 'audio_id': None}\n"
     ]
    }
   ],
   "source": [
    "terms[1].sentences[0].print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebc642-a7c3-42dc-a113-2bf0253bd017",
   "metadata": {},
   "source": [
    "## Add translation data to the `Terms`\n",
    "Provided that there is translation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd7cd059-7a3b-463c-97e9-536a33083ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_translations(tsvreader, terms, limit=2):\n",
    "    sentences_by_id = defaultdict(list)\n",
    "    for t in terms:\n",
    "        for s in t.sentences:\n",
    "            sentences_by_id[s.tatoeba_id].append(s)\n",
    "    for row in tsvreader:\n",
    "        sentence_id = row[0]\n",
    "        translation = row[3]\n",
    "        if sentence_id in sentences_by_id:\n",
    "            sentences = sentences_by_id[sentence_id]\n",
    "            for s in sentences:\n",
    "                if len(s.translations) < limit:\n",
    "                    s.translations.append(translation)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c20499a1-5856-4287-b1b9-51568c688c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_file = 'Sentence pairs in German-English - 2024-12-13.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ba7e613-dcfc-4feb-9f3a-66f52106476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_translations(x, terms), translations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e75a0-2b96-419a-9de1-1fd8f5db346d",
   "metadata": {},
   "source": [
    "## Add audio data to the `Terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14dc1df6-34ef-499b-9952-e52c57750947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_audio_ids(tsvreader, terms):\n",
    "    sentence_by_id = {}\n",
    "    for t in terms:\n",
    "        for s in t.sentences:\n",
    "            sentence_by_id[s.tatoeba_id] = s\n",
    "    for row in tsvreader:\n",
    "        sentence_id = row[0]\n",
    "        audio_id = row[1]\n",
    "        if sentence_id in sentence_by_id:\n",
    "            s = sentence_by_id[sentence_id]\n",
    "            s.audio_id = audio_id\n",
    "            # Delete the key in case the data file\n",
    "            # has multiple audio ids for this sentence\n",
    "            sentence_by_id.pop(sentence_id)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3be0b522-9601-4721-bc6e-bda99083a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_id_file = 'sentences_with_audio.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0a5b5e4-bbb0-4466-8925-d479eccfec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tsv(lambda x: add_audio_ids(x, terms), audio_id_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb44d2-4f30-4210-be42-f304c41900f8",
   "metadata": {},
   "source": [
    "## Write terms to Anki-readble `.tsv`\n",
    "We'll only take two translations per sentence.\n",
    "The file should look something like\n",
    "```\n",
    "word_de | word_en | tags| sentence1_de | audio1_id | sentence1_tr1 | sentence1_tr2 | sentence2_de audio2_id | sentence2_tr1 | sentence2_tr2 | tags\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6643e778-bf76-4d8e-b051-6fba46620e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: something funky can happen if the headers and\n",
    "# max_translations / max_sentences don't match up!\n",
    "def create_anki_tsv(tsvwriter,\n",
    "                    terms,\n",
    "                    max_translations=1,  # max translations of word_en\n",
    "                    max_sentences=2,  # max example sentences\n",
    "                    format_audio=True, \n",
    "                    headers=None,\n",
    "                    tags=None):\n",
    "    if not headers:\n",
    "        headers = ['word_de',\n",
    "                   'word_en',\n",
    "                   'tags',\n",
    "                   'sentence1_de',\n",
    "                   'audio1_id',\n",
    "                   'sentence1_tr1',\n",
    "                   'sentence2_de',\n",
    "                   'audio2_id',\n",
    "                   'sentence2_tr1']\n",
    "    tsvwriter.writerow(headers)\n",
    "    for t in terms:\n",
    "        row = []  # one row per term\n",
    "        row.append(t.text)\n",
    "        row.append(t.translation)\n",
    "        row.append(tags)\n",
    "        for s in t.sentences[:max_sentences]:\n",
    "            row.append(s.text)\n",
    "            if s.audio_id and format_audio:\n",
    "                row.append('[sound:{}.mp3]'.format(s.audio_id))\n",
    "            elif s.audio_id:\n",
    "                row.append(s.audio_id)\n",
    "            else:\n",
    "                row.append('')\n",
    "            \n",
    "            row.extend(s.translations[:max_translations])\n",
    "            # need row padding in case there are less translations\n",
    "            # than the maximum allowed\n",
    "            row_padding = [''] * max(0, max_translations - len(s.translations))\n",
    "            row.extend(row_padding)\n",
    "        tsvwriter.writerow(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e2ac899-1b13-431c-9fb3-19a0ef79e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tsv = './appointments/wie-spät-ist-es_cards.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "791cd46c-feae-4cd9-be00-ca4553c025be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_tsv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    tsvwriter = csv.writer(f, delimiter='\\t')\n",
    "    tags = 'python nw::appointments::wie-spät-ist-es'\n",
    "    create_anki_tsv(tsvwriter, terms, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073b19c-567e-44b5-bc57-1d02a2ea297c",
   "metadata": {},
   "source": [
    "## Download Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff1d5474-508c-4497-96e2-84884c06c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIRECTORY = './appointments/wie-spät-ist-es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2cdb4a6-bbe0-450c-be58-2ead618b2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mp3s(terms,\n",
    "                 audio_url_template='https://tatoeba.org/audio/download/{0}',\n",
    "                 audio_directory=AUDIO_DIRECTORY):\n",
    "    \n",
    "    sentences = [s for t in terms for s in t.sentences if s.audio_id]\n",
    "    for s in sentences:\n",
    "        audio_id = s.audio_id\n",
    "        request_url = audio_url_template.format(audio_id)\n",
    "        mp3data_request = requests.get(request_url)\n",
    "        mp3data = mp3data_request.content\n",
    "        with open(f'{audio_directory}/{audio_id}.mp3', 'wb') as mp3file:\n",
    "            mp3file.write(mp3data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab6bc0c7-bef1-4e2b-bc3b-a6c7871e1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_mp3s(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260dd359-43da-4a8b-91a1-591ab4a09865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatoeba_de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
